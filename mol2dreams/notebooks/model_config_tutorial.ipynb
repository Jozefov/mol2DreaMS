{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "In this section, we’ll explore the model part of the YAML configuration file. This configuration defines how the neural network model is structured, including its layers and any pretrained weights.\n",
    "\n",
    "Here’s the model section from YAML file:\n",
    "```\n",
    "model:\n",
    "  pretrained_weights: \"path_to_best_model.pt\"\n",
    "  input_layer:\n",
    "    type: 'CONV_GNN'\n",
    "    params:\n",
    "      node_features: 84\n",
    "      embedding_size_reduced: 128\n",
    "  body_layer:\n",
    "    type: 'SKIPBLOCK_BODY'\n",
    "    params:\n",
    "      embedding_size_gnn: 128\n",
    "      embedding_size: 256\n",
    "      num_skipblocks: 7\n",
    "      pooling_fn: 'mean'\n",
    "  head_layer:\n",
    "    type: 'BidirectionalHeadLayer'\n",
    "    params:\n",
    "      input_size: 256\n",
    "      output_size: 1024\n",
    "```\n",
    "#### Overview\n",
    "\n",
    "\t•\tpretrained_weights: Path to the pretrained model weights. This is optional and used when you want to continue training or fine-tune an existing model.\n",
    "\t•\tinput_layer: Defines the type and parameters of the input layer of the model.\n",
    "\t•\tbody_layer: Defines the type and parameters of the body layer(s) of the model.\n",
    "\t•\thead_layer: Defines the type and parameters of the head layer of the model. The head layer can be omitted if not needed.\n",
    "\n",
    "#### Model Architecture\n",
    "\n",
    "The model is partitioned into three main sections:\n",
    "\n",
    "\t1.\tInput Layer\n",
    "\t2.\tBody Layer\n",
    "\t3.\tHead Layer\n",
    "\n",
    "This modular design allows different architectures by simply changing the configuration.\n",
    "\n",
    "#### 1. Input Layer\n",
    "\n",
    "\t•\tPurpose: Processes the input data (graph representations of molecules) and extracts initial features.\n",
    "\t•\tDefined in: mol2dreams/model/InputLayer.py\n",
    "\n",
    "Available Input Layers\n",
    "\n",
    "\t•\tCONV_GNN: Uses Graph Convolutional Networks (GCN) to process node features.\n",
    "\t•\tTRANSFORMER_CONV: Utilizes Transformer convolutional layers.\n",
    "\t•\tGAT: Graph Attention Networks for capturing complex relationships.\n",
    "\t•\tNEIMS: Placeholder for molecular fingerprints (pass-through, not used).\n",
    "\n",
    "Configuration Example\n",
    "```\n",
    "input_layer:\n",
    "  type: 'CONV_GNN'\n",
    "  params:\n",
    "    node_features: 84\n",
    "    embedding_size_reduced: 128\n",
    "```\n",
    "\t•\ttype: Specifies the input layer class to use.\n",
    "\t•\tparams: Parameters specific to the chosen input layer (serach in code for model subpackage, from example down, we use set only node_features and embedding_size_reduced).\n",
    "\n",
    "Code Snippet for CONV_GNN\n",
    "```\n",
    "class CONV_GNN(InputLayer):\n",
    "    def __init__(self, node_features, embedding_size_reduced):\n",
    "        super(CONV_GNN, self).__init__()\n",
    "        torch.manual_seed(42)\n",
    "```\n",
    "#### 2. Body Layer\n",
    "\n",
    "\t•\tPurpose: Acts as the core of the model, performing deep feature extraction and transformation.\n",
    "\t•\tDefined in: mol2dreams/model/BodyLayer.py\n",
    "\n",
    "Available Body Layers\n",
    "\n",
    "\t•\tSKIPBLOCK_BODY: Consists of multiple skip blocks, which help in training deeper networks by mitigating the vanishing gradient problem.\n",
    "\t•\tRegression_BODY: A fully connected network suitable for regression tasks.\n",
    "\n",
    "Configuration Example\n",
    "```\n",
    "body_layer:\n",
    "  type: 'SKIPBLOCK_BODY'\n",
    "  params:\n",
    "    embedding_size_gnn: 128\n",
    "    embedding_size: 256\n",
    "    num_skipblocks: 7\n",
    "    pooling_fn: 'mean'\n",
    "```\n",
    "\t•\ttype: Specifies the body layer class to use.\n",
    "\t•\tparams: Parameters specific to the chosen body layer.\n",
    "\n",
    "Parameters Explained\n",
    "\n",
    "\t•\tembedding_size_gnn: The size of the embeddings from the input layer.\n",
    "\t•\tembedding_size: The size of the embeddings within the body layer.\n",
    "\t•\tnum_skipblocks: Number of skip blocks in the body layer.\n",
    "\t•\tpooling_fn: The pooling function to use from GNN input layer (mean, max, or add).\n",
    "\n",
    "Code Snippet for SKIPBLOCK_BODY\n",
    "```\n",
    "class SKIPBLOCK_BODY(BodyLayer):\n",
    "    def __init__(self, embedding_size_gnn, embedding_size, num_skipblocks=7, pooling_fn='mean'):\n",
    "        super(SKIPBLOCK_BODY, self).__init__()\n",
    "        torch.manual_seed(42)\n",
    "```\n",
    "\n",
    "#### 3. Head Layer\n",
    "\n",
    "\t•\tPurpose: Transforms the output of the body layer to the desired output size or performs final computations.\n",
    "\t•\tDefined in: mol2dreams/model/HeadLayer.py\n",
    "\t•\tNote: The head layer can be omitted if not needed; an identity layer (IdentityHead) will be used by default.\n",
    "\n",
    "Available Head Layers\n",
    "\n",
    "\t•\tBidirectionalHeadLayer: Combines forward and backward predictions using gating mechanisms.\n",
    "\t•\tIdentityHead: Pass-through layer that outputs the input as-is.\n",
    "\n",
    "Configuration Example\n",
    "```\n",
    "head_layer:\n",
    "  type: 'BidirectionalHeadLayer'\n",
    "  params:\n",
    "    input_size: 256\n",
    "    output_size: 1024\n",
    "```\n",
    "\t•\ttype: Specifies the head layer class to use.\n",
    "\t•\tparams: Parameters specific to the chosen head layer.\n",
    "\n",
    "Code Snippet for BidirectionalHeadLayer\n",
    "```\n",
    "class BidirectionalHeadLayer(HeadLayer):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(BidirectionalHeadLayer, self).__init__()\n",
    "        torch.manual_seed(42)\n",
    "\n",
    "```\n",
    "#### Model Assembly\n",
    "\n",
    "The model is assembled by combining the input, body, and head layers.\n",
    "\n",
    "Mol2DreaMS Class\n",
    "\n",
    "\t•\tDefined in: mol2dreams/model/mol2dreams.py\n",
    "\t•\tPurpose: Wraps the input, body, and head layers into a single model.\n",
    "\n",
    "Code Snippet\n",
    "```\n",
    "class Mol2DreaMS(nn.Module):\n",
    "    def __init__(self, input_layer: nn.Module, body_layer: nn.Module, head_layer: nn.Module = None):\n",
    "        super(Mol2DreaMS, self).__init__()\n",
    "\n",
    "```\n",
    "Building the Model from Configuration\n",
    "\n",
    "The model is built using the build_model_from_config function, which parses the YAML configuration and constructs the model accordingly.\n",
    "\n",
    "#### Using the Configuration\n",
    "\n",
    "When setting up your YAML configuration, you can customize your model architecture by:\n",
    "\n",
    "\t•\tSelecting Different Layer Types:\n",
    "\t•\tChange the type field under input_layer, body_layer, or head_layer to use different implementations.\n",
    "\t•\tAdjusting Parameters:\n",
    "\t•\tModify the params dictionaries to adjust hyperparameters like embedding sizes, number of layers, etc.\n",
    "\t•\tIncluding Pretrained Weights:\n",
    "\t•\tSpecify the pretrained_weights path if you want to continue training or fine-tune an existing model.\n",
    "\n",
    "Example: Creating a Model from Scratch\n",
    "\n",
    "If you don’t want to use pretrained weights, you can omit the pretrained_weights field:\n",
    "```\n",
    "model:\n",
    "  input_layer:\n",
    "    type: 'CONV_GNN'\n",
    "    params:\n",
    "      node_features: 84\n",
    "      embedding_size_reduced: 128\n",
    "  body_layer:\n",
    "    type: 'SKIPBLOCK_BODY'\n",
    "    params:\n",
    "      embedding_size_gnn: 128\n",
    "      embedding_size: 256\n",
    "      num_skipblocks: 7\n",
    "      pooling_fn: 'mean'\n",
    "  head_layer:\n",
    "    type: 'BidirectionalHeadLayer'\n",
    "    params:\n",
    "      input_size: 256\n",
    "      output_size: 1024\n",
    "```\n",
    "Extending the Model\n",
    "\n",
    "You can extend the model by:\n",
    "\n",
    "\t•\tAdding New Layer Types:\n",
    "\t•\tImplement new classes in the respective modules (InputLayer.py, BodyLayer.py, HeadLayer.py).\n",
    "\t•\tUpdate the configuration (yaml) to use your new layer types.\n",
    "\t•\tCustomizing Existing Layers:\n",
    "\t•\tModify existing layer classes to adjust their behavior.\n",
    "\t•\tUpdate parameters in the configuration as needed.\n"
   ],
   "id": "463adb64f12ee849"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9d9a2fbd339c7cc6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
