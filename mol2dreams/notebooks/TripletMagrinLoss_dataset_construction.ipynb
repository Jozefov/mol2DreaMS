{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-09T07:04:21.566863Z",
     "start_time": "2024-10-09T07:04:20.260778Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matchms.importing import load_from_mgf"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T07:04:21.572629Z",
     "start_time": "2024-10-09T07:04:21.570189Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_mgf_with_folds(mgf_path):\n",
    "\n",
    "    spectra = list(load_from_mgf(mgf_path))\n",
    "    records = []\n",
    "    for spec in spectra:\n",
    "        record = spec.to_dict()\n",
    "        records.append(record)\n",
    "    df = pd.DataFrame(records)\n",
    "\n",
    "    if 'fold' not in df.columns:\n",
    "        raise ValueError(\"fold column is missing. Ensure the dataset has been split into train/val/test.\")\n",
    "    \n",
    "    df.collision_energy = df.collision_energy.astype(float)\n",
    "    df.parent_mass = df.parent_mass.astype(float)\n",
    "    df.precursor_mz = df.precursor_mz.astype(float)\n",
    "    \n",
    "    return df\n"
   ],
   "id": "a81f9ee170c321b5",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T07:04:59.645483Z",
     "start_time": "2024-10-09T07:04:21.578455Z"
    }
   },
   "cell_type": "code",
   "source": [
    "spectra_path = \"../../data/data/MassSpecGym.mgf\"\n",
    "df = load_mgf_with_folds(spectra_path)\n",
    "print(df.head())"
   ],
   "id": "7623c4cf5ad80a44",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             identifier                                         smiles  \\\n",
      "0  MassSpecGymID0000001  CC(=O)N[C@@H](CC1=CC=CC=C1)C2=CC(=CC(=O)O2)OC   \n",
      "1  MassSpecGymID0000002  CC(=O)N[C@@H](CC1=CC=CC=C1)C2=CC(=CC(=O)O2)OC   \n",
      "2  MassSpecGymID0000003  CC(=O)N[C@@H](CC1=CC=CC=C1)C2=CC(=CC(=O)O2)OC   \n",
      "3  MassSpecGymID0000004  CC(=O)N[C@@H](CC1=CC=CC=C1)C2=CC(=CC(=O)O2)OC   \n",
      "4  MassSpecGymID0000005  CC(=O)N[C@@H](CC1=CC=CC=C1)C2=CC(=CC(=O)O2)OC   \n",
      "\n",
      "         inchikey    formula precursor_formula  parent_mass  precursor_mz  \\\n",
      "0  VFMQMACUYWGDOJ  C16H17NO4         C16H18NO4   287.115224      288.1225   \n",
      "1  VFMQMACUYWGDOJ  C16H17NO4         C16H18NO4   287.115224      288.1225   \n",
      "2  VFMQMACUYWGDOJ  C16H17NO4         C16H18NO4   287.115224      288.1225   \n",
      "3  VFMQMACUYWGDOJ  C16H17NO4         C16H18NO4   287.115224      288.1225   \n",
      "4  VFMQMACUYWGDOJ  C16H17NO4         C16H18NO4   287.115224      288.1225   \n",
      "\n",
      "   adduct instrument_type  collision_energy   fold simulation_challenge  \\\n",
      "0  [M+H]+        Orbitrap              30.0  train                 True   \n",
      "1  [M+H]+        Orbitrap              20.0  train                 True   \n",
      "2  [M+H]+        Orbitrap              40.0  train                 True   \n",
      "3  [M+H]+        Orbitrap              55.0  train                 True   \n",
      "4  [M+H]+        Orbitrap              10.0  train                 True   \n",
      "\n",
      "                                          peaks_json  \n",
      "0  [[91.0542, 0.24524524524524524], [125.0233, 1....  \n",
      "1  [[91.0542, 0.0990990990990991], [125.0233, 0.2...  \n",
      "2  [[69.0343, 0.03403403403403404], [91.0542, 0.3...  \n",
      "3  [[69.0343, 0.17917917917917917], [91.0542, 0.4...  \n",
      "4  [[91.0542, 0.07807807807807808], [125.0233, 0....  \n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T07:04:59.677827Z",
     "start_time": "2024-10-09T07:04:59.672860Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def construct_triplets(df, examples_number=5):\n",
    "    # Filter the DataFrame\n",
    "    df_filtered = df[\n",
    "        (df['fold'] == 'train') &\n",
    "        (df['adduct'] == '[M+H]+') &\n",
    "        (df['collision_energy'] == 60.0)\n",
    "    ].reset_index(drop=True)\n",
    "\n",
    "    print(f\"Filtered dataset size: {len(df_filtered)} spectra\")\n",
    "\n",
    "    if len(df_filtered) == 0:\n",
    "        print(\"No spectra found after filtering. Exiting.\")\n",
    "        return None\n",
    "\n",
    "    # Compute the 14-character prefix of the InChI key\n",
    "    df_filtered['inchikey_prefix'] = df_filtered['inchikey'].str[:14]\n",
    "\n",
    "    # Build mappings\n",
    "    # Map from InChI key prefixes to lists of identifiers\n",
    "    inchikey_to_identifiers = df_filtered.groupby('inchikey_prefix')['identifier'].apply(list).to_dict()\n",
    "    \n",
    "    # Map from identifiers to InChI key prefixes and parent masses\n",
    "    identifier_to_inchikey = df_filtered.set_index('identifier')['inchikey_prefix'].to_dict()\n",
    "    identifier_to_parent_mass = df_filtered.set_index('identifier')['parent_mass'].to_dict()\n",
    "\n",
    "    # Build a DataFrame of parent masses and identifiers\n",
    "    mass_df = df_filtered[['identifier', 'parent_mass', 'inchikey_prefix']].copy()\n",
    "    mass_df = mass_df.sort_values('parent_mass').reset_index(drop=True)\n",
    "\n",
    "    # For each anchor, find positive and negative examples\n",
    "    data = []\n",
    "    for idx, row in df_filtered.iterrows():\n",
    "        anchor_id = row['identifier']\n",
    "        anchor_inchikey = row['inchikey_prefix']\n",
    "        anchor_parent_mass = row['parent_mass']\n",
    "        anchor_smiles = row['smiles']\n",
    "\n",
    "        # Find positive examples (same InChI key prefix, different identifier)\n",
    "        positive_ids = inchikey_to_identifiers[anchor_inchikey].copy()\n",
    "        positive_ids = [pid for pid in positive_ids if pid != anchor_id]\n",
    "\n",
    "        # Randomly select up to 5 positive examples\n",
    "        if len(positive_ids) > examples_number:\n",
    "            positive_ids = np.random.choice(positive_ids, examples_number, replace=False).tolist()\n",
    "\n",
    "        # Find negative examples (different InChI key prefix, parent mass within Â±5 Da)\n",
    "        mass_lower = anchor_parent_mass - 5.0\n",
    "        mass_upper = anchor_parent_mass + 5.0\n",
    "\n",
    "        # Candidates within the mass range\n",
    "        mass_candidates = mass_df[\n",
    "            (mass_df['parent_mass'] >= mass_lower) &\n",
    "            (mass_df['parent_mass'] <= mass_upper)\n",
    "        ]\n",
    "\n",
    "        # Exclude entries with the same InChI key prefix and the anchor itself\n",
    "        negative_candidates = mass_candidates[\n",
    "            (mass_candidates['inchikey_prefix'] != anchor_inchikey) &\n",
    "            (mass_candidates['identifier'] != anchor_id)\n",
    "        ]\n",
    "\n",
    "        negative_ids = negative_candidates['identifier'].tolist()\n",
    "\n",
    "        # Randomly select up to 5 negative examples\n",
    "        if len(negative_ids) > examples_number:\n",
    "            negative_ids = np.random.choice(negative_ids, examples_number, replace=False).tolist()\n",
    "\n",
    "        # Append the results\n",
    "        data.append({\n",
    "            'anchor_smiles': anchor_smiles,\n",
    "            'anchor_id': anchor_id,\n",
    "            'positive_ids': positive_ids,\n",
    "            'negative_ids': negative_ids\n",
    "        })\n",
    "\n",
    "    # Convert the list to a DataFrame\n",
    "    triplets_df = pd.DataFrame(data)\n",
    "\n",
    "    print(f\"Constructed triplets for {len(triplets_df)} anchors.\")\n",
    "\n",
    "    return triplets_df\n"
   ],
   "id": "3f9b048da8aa94ed",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T07:05:03.996691Z",
     "start_time": "2024-10-09T07:04:59.701834Z"
    }
   },
   "cell_type": "code",
   "source": [
    "triplets_df = construct_triplets(df)\n",
    "print(triplets_df.head())"
   ],
   "id": "73044d6308386f0b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered dataset size: 11186 spectra\n",
      "Constructed triplets for 11186 anchors.\n",
      "                                       anchor_smiles             anchor_id  \\\n",
      "0  CC(C)[C@H]1C(=O)O[C@@H](C(=O)N([C@H](C(=O)O[C@...  MassSpecGymID0000261   \n",
      "1  C[C@@H]1CC2=C(C=C(C(=C2C(=O)O1)O)C(=O)N[C@@H](...  MassSpecGymID0000740   \n",
      "2  CC[C@H](C)C(=O)O[C@H]1CCC=C2[C@H]1[C@H]([C@H](...  MassSpecGymID0000882   \n",
      "3       CC1=CC2=C(C(=C1)O)C(=O)C3=C(C2=O)C=C(C=C3O)O  MassSpecGymID0001133   \n",
      "4  COC1=C2C3=C(C(=O)CC3)C(=O)OC2=C4[C@@H]5C=CO[C@...  MassSpecGymID0001358   \n",
      "\n",
      "  positive_ids                                       negative_ids  \n",
      "0           []  [MassSpecGymID0195900, MassSpecGymID0229559, M...  \n",
      "1           []  [MassSpecGymID0221313, MassSpecGymID0153479, M...  \n",
      "2           []  [MassSpecGymID0224162, MassSpecGymID0157766, M...  \n",
      "3           []  [MassSpecGymID0054786, MassSpecGymID0157013, M...  \n",
      "4           []  [MassSpecGymID0209277, MassSpecGymID0055962, M...  \n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T07:05:04.058828Z",
     "start_time": "2024-10-09T07:05:04.046655Z"
    }
   },
   "cell_type": "code",
   "source": [
    "triplets_df['num_positive'] = triplets_df['positive_ids'].apply(len)\n",
    "triplets_df['num_negative'] = triplets_df['negative_ids'].apply(len)\n",
    "\n",
    "# Compute value counts for positive_ids\n",
    "positive_counts = triplets_df['num_positive'].value_counts().sort_index()\n",
    "print(\"Positive IDs counts:\")\n",
    "print(positive_counts)\n",
    "\n",
    "# Compute value counts for negative_ids\n",
    "negative_counts = triplets_df['num_negative'].value_counts().sort_index()\n",
    "print(\"\\nNegative IDs counts:\")\n",
    "print(negative_counts)\n",
    "\n",
    "# Compute unique compounds \n",
    "unique_compounds = triplets_df['anchor_smiles'].unique()\n",
    "print(\"\\nUnique compounds:\")\n",
    "print(len(unique_compounds))"
   ],
   "id": "5f6673f8345b75b9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive IDs counts:\n",
      "num_positive\n",
      "0    7467\n",
      "1    1756\n",
      "2    1137\n",
      "3     440\n",
      "4     190\n",
      "5     196\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Negative IDs counts:\n",
      "num_negative\n",
      "0        2\n",
      "1       13\n",
      "2       11\n",
      "3        8\n",
      "4       12\n",
      "5    11140\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Unique compounds:\n",
      "9154\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Join with embedding",
   "id": "421bd2c3e20d5a5a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T07:05:07.942093Z",
     "start_time": "2024-10-09T07:05:04.066051Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from mol2dreams.utils.data import prepare_datasets\n",
    "from dreams.utils.data import MSData\n",
    "from dreams.definitions import DREAMS_EMBEDDING"
   ],
   "id": "ecb5ff6ca07d0608",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbook/UTILS/anaconda3/envs/mol2dreams/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Determination of memory status is not supported on this \n",
      " platform, measuring for memoryleaks will never fail\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T07:05:08.108013Z",
     "start_time": "2024-10-09T07:05:07.970712Z"
    }
   },
   "cell_type": "code",
   "source": [
    "hdf5_path = \"../../data/data/MassSpecGym_DreaMS.hdf5\"\n",
    "msdata = MSData.from_hdf5(hdf5_path, prec_mz_col='precursor_mz')\n",
    "embs = msdata[DREAMS_EMBEDDING]\n",
    "embs.shape"
   ],
   "id": "187e015e72c6b744",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(213548, 1024)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T07:05:13.892777Z",
     "start_time": "2024-10-09T07:05:08.135249Z"
    }
   },
   "cell_type": "code",
   "source": [
    "extra_features = ['COLLISION_ENERGY', 'adduct', 'precursor_mz']\n",
    "# Prepare datasets\n",
    "datasets = prepare_datasets(\n",
    "    msdata=msdata, \n",
    "    embs=embs, \n",
    "    splits=['train', 'val'],  # Include 'test' if present\n",
    "    smiles_col='smiles', \n",
    "    embedding_col='DreaMS_embedding', \n",
    "    fold_col='FOLD'\n",
    ")"
   ],
   "id": "b54acdab4909c558",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing split 'train' with 194119 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Featurizing train: 100%|ââââââââââ| 194119/194119 [00:03<00:00, 52873.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing split 'val' with 19429 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Featurizing val: 100%|ââââââââââ| 19429/19429 [00:00<00:00, 49226.48it/s]\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T07:05:13.923789Z",
     "start_time": "2024-10-09T07:05:13.921924Z"
    }
   },
   "cell_type": "code",
   "source": "train_data = datasets['train']",
   "id": "25f770538807fa62",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T07:05:13.980821Z",
     "start_time": "2024-10-09T07:05:13.951005Z"
    }
   },
   "cell_type": "code",
   "source": "identifier_to_data = {entry['IDENTIFIER']: entry for entry in train_data}",
   "id": "d4951a91e703a84e",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T07:05:14.033190Z",
     "start_time": "2024-10-09T07:05:14.014543Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Anchors\n",
    "anchor_ids = set(triplets_df['anchor_id'])\n",
    "\n",
    "# Positives\n",
    "positive_ids_set = set([pid for sublist in triplets_df['positive_ids'] for pid in sublist])\n",
    "\n",
    "# Negatives\n",
    "negative_ids_set = set([nid for sublist in triplets_df['negative_ids'] for nid in sublist])\n",
    "\n",
    "# Union of all identifiers\n",
    "all_triplet_ids = anchor_ids.union(positive_ids_set).union(negative_ids_set)"
   ],
   "id": "6361d4e6e4f71fd8",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T07:05:14.093219Z",
     "start_time": "2024-10-09T07:05:14.081143Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset_ids = set(identifier_to_data.keys())\n",
    "identifiers_not_in_datasets = all_triplet_ids - dataset_ids\n",
    "\n",
    "if identifiers_not_in_datasets:\n",
    "    print(f\"Identifiers in triplets not in datasets: {len(identifiers_not_in_datasets)}\")\n",
    "    print(identifiers_not_in_datasets)\n",
    "else:\n",
    "    print(\"All identifiers in triplets are present in datasets.\")"
   ],
   "id": "913d4d998f22cc52",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All identifiers in triplets are present in datasets.\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T07:09:52.614360Z",
     "start_time": "2024-10-09T07:09:52.551785Z"
    }
   },
   "cell_type": "code",
   "source": [
    "identifier_to_embedding = {entry['IDENTIFIER']: entry['embedding'] for entry in train_data}\n",
    "identifier_to_smiles ={entry['IDENTIFIER']: entry['smiles'] for entry in train_data}"
   ],
   "id": "d3e8794bcdb1ed01",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T07:10:09.050894Z",
     "start_time": "2024-10-09T07:10:09.047997Z"
    }
   },
   "cell_type": "code",
   "source": "len(identifier_to_embedding), len(identifier_to_smiles)",
   "id": "f854e4d701e751e5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(194119, 194119)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T07:05:14.474923Z",
     "start_time": "2024-10-09T07:05:14.473639Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "98bd9b639c84b043",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
