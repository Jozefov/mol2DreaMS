{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T12:30:09.861171Z",
     "start_time": "2024-10-10T12:30:08.541673Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import yaml\n",
    "from mol2dreams.utils.parser import (\n",
    "    build_model_from_config,\n",
    "    build_trainer_from_config)\n",
    "from mol2dreams.datasets.TripletDataset import TripletDataset"
   ],
   "id": "5fa08241e1195bb4",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T12:30:09.868410Z",
     "start_time": "2024-10-10T12:30:09.863893Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(\"/Users/macbook/CODE/mol2DreaMS/mol2dreams/configs/local_config_adversarial_fine_tune_triplet.yaml\") as stream:\n",
    "    config = yaml.safe_load(stream)"
   ],
   "id": "610b3e7b91c034c5",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T12:30:12.742729Z",
     "start_time": "2024-10-10T12:30:09.903432Z"
    }
   },
   "cell_type": "code",
   "source": "trainer = build_trainer_from_config(config)",
   "id": "a0362df2138eaeff",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights from /Users/macbook/CODE/mol2DreaMS/data/logs/mol2dreams/20241010_115915_mol2dreams/best_model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbook/UTILS/anaconda3/envs/mol2dreams/lib/python3.11/site-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T12:30:15.378859Z",
     "start_time": "2024-10-10T12:30:12.748110Z"
    }
   },
   "cell_type": "code",
   "source": "trainer.test()",
   "id": "ce0023247484cba",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.0587, Triplet Loss: 0.2872, Adv Loss: 0.7714, Pos Sim: 1.0000, Neg Sim: 0.8128\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T12:31:27.959212Z",
     "start_time": "2024-10-10T12:30:15.439601Z"
    }
   },
   "cell_type": "code",
   "source": "trainer.train()",
   "id": "bb674042f4530157",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Batch [0/117], Total Loss: 2.3727, Triplet Loss: 0.3554, Adv Loss: 2.0173, Disc Loss: 9.3984\n",
      "Epoch [1/10], Batch [10/117], Total Loss: 0.7829, Triplet Loss: 0.1475, Adv Loss: 0.6354, Disc Loss: 2.5115\n",
      "Epoch [1/10], Batch [20/117], Total Loss: 1.7817, Triplet Loss: 0.1216, Adv Loss: 1.6602, Disc Loss: 0.6035\n",
      "Epoch [1/10], Batch [30/117], Total Loss: 1.2182, Triplet Loss: 0.1196, Adv Loss: 1.0986, Disc Loss: 0.7624\n",
      "Epoch [1/10], Batch [40/117], Total Loss: 1.0566, Triplet Loss: 0.1124, Adv Loss: 0.9442, Disc Loss: 0.7816\n",
      "Epoch [1/10], Batch [50/117], Total Loss: 1.0650, Triplet Loss: 0.1037, Adv Loss: 0.9613, Disc Loss: 0.6117\n",
      "Epoch [1/10], Batch [60/117], Total Loss: 1.0831, Triplet Loss: 0.1085, Adv Loss: 0.9746, Disc Loss: 0.5426\n",
      "Epoch [1/10], Batch [70/117], Total Loss: 1.1182, Triplet Loss: 0.0939, Adv Loss: 1.0243, Disc Loss: 0.4911\n",
      "Epoch [1/10], Batch [80/117], Total Loss: 1.2241, Triplet Loss: 0.1273, Adv Loss: 1.0968, Disc Loss: 0.4834\n",
      "Epoch [1/10], Batch [90/117], Total Loss: 1.2960, Triplet Loss: 0.1013, Adv Loss: 1.1947, Disc Loss: 0.4332\n",
      "Epoch [1/10], Batch [100/117], Total Loss: 1.4006, Triplet Loss: 0.1205, Adv Loss: 1.2800, Disc Loss: 0.4109\n",
      "Epoch [1/10], Batch [110/117], Total Loss: 1.4715, Triplet Loss: 0.0972, Adv Loss: 1.3743, Disc Loss: 0.3245\n",
      "Epoch [1/10] Completed. Avg Total Loss: 1.3223, Avg Triplet Loss: 0.1215, Avg Adv Loss: 1.2009, Avg Disc Loss: 0.9432\n",
      "Epoch [2/10], Batch [0/117], Total Loss: 1.5661, Triplet Loss: 0.1018, Adv Loss: 1.4643, Disc Loss: 0.2918\n",
      "Epoch [2/10], Batch [10/117], Total Loss: 1.7174, Triplet Loss: 0.1041, Adv Loss: 1.6133, Disc Loss: 0.2637\n",
      "Epoch [2/10], Batch [20/117], Total Loss: 1.8974, Triplet Loss: 0.1076, Adv Loss: 1.7898, Disc Loss: 0.2004\n",
      "Epoch [2/10], Batch [30/117], Total Loss: 2.1067, Triplet Loss: 0.1098, Adv Loss: 1.9969, Disc Loss: 0.1697\n",
      "Epoch [2/10], Batch [40/117], Total Loss: 2.3544, Triplet Loss: 0.1166, Adv Loss: 2.2378, Disc Loss: 0.1317\n",
      "Epoch [2/10], Batch [50/117], Total Loss: 2.5970, Triplet Loss: 0.1234, Adv Loss: 2.4736, Disc Loss: 0.1161\n",
      "Epoch [2/10], Batch [60/117], Total Loss: 2.8260, Triplet Loss: 0.1072, Adv Loss: 2.7189, Disc Loss: 0.0901\n",
      "Epoch [2/10], Batch [70/117], Total Loss: 3.0959, Triplet Loss: 0.1492, Adv Loss: 2.9467, Disc Loss: 0.0750\n",
      "Epoch [2/10], Batch [80/117], Total Loss: 3.2856, Triplet Loss: 0.1240, Adv Loss: 3.1616, Disc Loss: 0.0677\n",
      "Epoch [2/10], Batch [90/117], Total Loss: 3.5190, Triplet Loss: 0.1744, Adv Loss: 3.3446, Disc Loss: 0.0561\n",
      "Epoch [2/10], Batch [100/117], Total Loss: 3.6192, Triplet Loss: 0.1159, Adv Loss: 3.5033, Disc Loss: 0.0438\n",
      "Epoch [2/10], Batch [110/117], Total Loss: 3.7431, Triplet Loss: 0.1090, Adv Loss: 3.6341, Disc Loss: 0.0445\n",
      "Epoch [2/10] Completed. Avg Total Loss: 2.7511, Avg Triplet Loss: 0.1187, Avg Adv Loss: 2.6324, Avg Disc Loss: 0.1238\n",
      "Validation Loss: 3.7911, Triplet Loss: 0.1047, Adv Loss: 3.6864, Pos Sim: 1.0000, Neg Sim: 0.9953\n",
      "Validation Loss after Epoch 2: 3.7911\n",
      "Best model saved at epoch 2 with validation loss inf\n",
      "Model checkpoint saved at ../../data/logs/mol2dreams/20241010_143012_mol2dreams/model_epoch_2.pt\n",
      "Epoch [3/10], Batch [0/117], Total Loss: 3.7813, Triplet Loss: 0.0832, Adv Loss: 3.6981, Disc Loss: 0.0783\n",
      "Epoch [3/10], Batch [10/117], Total Loss: 3.8364, Triplet Loss: 0.0960, Adv Loss: 3.7404, Disc Loss: 0.0545\n",
      "Epoch [3/10], Batch [20/117], Total Loss: 3.9588, Triplet Loss: 0.1907, Adv Loss: 3.7681, Disc Loss: 0.0844\n",
      "Epoch [3/10], Batch [30/117], Total Loss: 4.7457, Triplet Loss: 0.2731, Adv Loss: 4.4726, Disc Loss: 0.0538\n",
      "Epoch [3/10], Batch [40/117], Total Loss: 4.0583, Triplet Loss: 0.1969, Adv Loss: 3.8614, Disc Loss: 0.0899\n",
      "Epoch [3/10], Batch [50/117], Total Loss: 3.7473, Triplet Loss: 0.2392, Adv Loss: 3.5081, Disc Loss: 0.0639\n",
      "Epoch [3/10], Batch [60/117], Total Loss: 3.5184, Triplet Loss: 0.2580, Adv Loss: 3.2604, Disc Loss: 0.0855\n",
      "Epoch [3/10], Batch [70/117], Total Loss: 4.0639, Triplet Loss: 0.1592, Adv Loss: 3.9047, Disc Loss: 0.0540\n",
      "Epoch [3/10], Batch [80/117], Total Loss: 3.6407, Triplet Loss: 0.2164, Adv Loss: 3.4244, Disc Loss: 0.0639\n",
      "Epoch [3/10], Batch [90/117], Total Loss: 3.7564, Triplet Loss: 0.2656, Adv Loss: 3.4908, Disc Loss: 0.0774\n",
      "Epoch [3/10], Batch [100/117], Total Loss: 3.5334, Triplet Loss: 0.2275, Adv Loss: 3.3059, Disc Loss: 0.0616\n",
      "Epoch [3/10], Batch [110/117], Total Loss: 3.4275, Triplet Loss: 0.1164, Adv Loss: 3.3112, Disc Loss: 0.0670\n",
      "Epoch [3/10] Completed. Avg Total Loss: 3.9045, Avg Triplet Loss: 0.2047, Avg Adv Loss: 3.6998, Avg Disc Loss: 0.0689\n",
      "Epoch [4/10], Batch [0/117], Total Loss: 3.8371, Triplet Loss: 0.1278, Adv Loss: 3.7093, Disc Loss: 0.0622\n",
      "Epoch [4/10], Batch [10/117], Total Loss: 3.7506, Triplet Loss: 0.2591, Adv Loss: 3.4915, Disc Loss: 0.0763\n",
      "Epoch [4/10], Batch [20/117], Total Loss: 3.4632, Triplet Loss: 0.2037, Adv Loss: 3.2595, Disc Loss: 0.0852\n",
      "Epoch [4/10], Batch [30/117], Total Loss: 3.2679, Triplet Loss: 0.1409, Adv Loss: 3.1270, Disc Loss: 0.0896\n",
      "Epoch [4/10], Batch [40/117], Total Loss: 3.4578, Triplet Loss: 0.2170, Adv Loss: 3.2408, Disc Loss: 0.0750\n",
      "Epoch [4/10], Batch [50/117], Total Loss: 3.3119, Triplet Loss: 0.1605, Adv Loss: 3.1514, Disc Loss: 0.0811\n",
      "Epoch [4/10], Batch [60/117], Total Loss: 3.3830, Triplet Loss: 0.1136, Adv Loss: 3.2694, Disc Loss: 0.0654\n",
      "Epoch [4/10], Batch [70/117], Total Loss: 3.8838, Triplet Loss: 0.1433, Adv Loss: 3.7406, Disc Loss: 0.0832\n",
      "Epoch [4/10], Batch [80/117], Total Loss: 4.1007, Triplet Loss: 0.1658, Adv Loss: 3.9348, Disc Loss: 0.0521\n",
      "Epoch [4/10], Batch [90/117], Total Loss: 3.5986, Triplet Loss: 0.1133, Adv Loss: 3.4853, Disc Loss: 0.0666\n",
      "Epoch [4/10], Batch [100/117], Total Loss: 3.4963, Triplet Loss: 0.1063, Adv Loss: 3.3900, Disc Loss: 0.0517\n",
      "Epoch [4/10], Batch [110/117], Total Loss: 3.4815, Triplet Loss: 0.3100, Adv Loss: 3.1715, Disc Loss: 0.0642\n",
      "Epoch [4/10] Completed. Avg Total Loss: 3.6015, Avg Triplet Loss: 0.1681, Avg Adv Loss: 3.4335, Avg Disc Loss: 0.0722\n",
      "Validation Loss: 3.2351, Triplet Loss: 0.1066, Adv Loss: 3.1284, Pos Sim: 1.0000, Neg Sim: 0.9934\n",
      "Validation Loss after Epoch 4: 3.2351\n",
      "Best model saved at epoch 4 with validation loss inf\n",
      "Model checkpoint saved at ../../data/logs/mol2dreams/20241010_143012_mol2dreams/model_epoch_4.pt\n",
      "Epoch [5/10], Batch [0/117], Total Loss: 3.7168, Triplet Loss: 0.1078, Adv Loss: 3.6091, Disc Loss: 0.0695\n",
      "Epoch [5/10], Batch [10/117], Total Loss: 4.2891, Triplet Loss: 0.1276, Adv Loss: 4.1615, Disc Loss: 0.0273\n",
      "Epoch [5/10], Batch [20/117], Total Loss: 4.6285, Triplet Loss: 0.1710, Adv Loss: 4.4575, Disc Loss: 0.0556\n",
      "Epoch [5/10], Batch [30/117], Total Loss: 4.2577, Triplet Loss: 0.1738, Adv Loss: 4.0839, Disc Loss: 0.0412\n",
      "Epoch [5/10], Batch [40/117], Total Loss: 4.1383, Triplet Loss: 0.1919, Adv Loss: 3.9464, Disc Loss: 0.0333\n",
      "Epoch [5/10], Batch [50/117], Total Loss: 4.1679, Triplet Loss: 0.1032, Adv Loss: 4.0647, Disc Loss: 0.0395\n",
      "Epoch [5/10], Batch [60/117], Total Loss: 4.1354, Triplet Loss: 0.1343, Adv Loss: 4.0010, Disc Loss: 0.0365\n",
      "Epoch [5/10], Batch [70/117], Total Loss: 4.1755, Triplet Loss: 0.1568, Adv Loss: 4.0187, Disc Loss: 0.0368\n",
      "Epoch [5/10], Batch [80/117], Total Loss: 5.3467, Triplet Loss: 0.1972, Adv Loss: 5.1495, Disc Loss: 0.0323\n",
      "Epoch [5/10], Batch [90/117], Total Loss: 4.5178, Triplet Loss: 0.2043, Adv Loss: 4.3136, Disc Loss: 0.0397\n",
      "Epoch [5/10], Batch [100/117], Total Loss: 4.3157, Triplet Loss: 0.3125, Adv Loss: 4.0032, Disc Loss: 0.0722\n",
      "Epoch [5/10], Batch [110/117], Total Loss: 3.5470, Triplet Loss: 0.1430, Adv Loss: 3.4041, Disc Loss: 0.0452\n",
      "Epoch [5/10] Completed. Avg Total Loss: 4.3237, Avg Triplet Loss: 0.1643, Avg Adv Loss: 4.1594, Avg Disc Loss: 0.0434\n",
      "Epoch [6/10], Batch [0/117], Total Loss: 4.3930, Triplet Loss: 0.1448, Adv Loss: 4.2483, Disc Loss: 0.0549\n",
      "Epoch [6/10], Batch [10/117], Total Loss: 3.4532, Triplet Loss: 0.1433, Adv Loss: 3.3100, Disc Loss: 0.0801\n",
      "Epoch [6/10], Batch [20/117], Total Loss: 4.6661, Triplet Loss: 0.1413, Adv Loss: 4.5249, Disc Loss: 0.0452\n",
      "Epoch [6/10], Batch [30/117], Total Loss: 4.3988, Triplet Loss: 0.1270, Adv Loss: 4.2717, Disc Loss: 0.0456\n",
      "Epoch [6/10], Batch [40/117], Total Loss: 4.2325, Triplet Loss: 0.1281, Adv Loss: 4.1044, Disc Loss: 0.0330\n",
      "Epoch [6/10], Batch [50/117], Total Loss: 4.6442, Triplet Loss: 0.2314, Adv Loss: 4.4128, Disc Loss: 0.0370\n",
      "Epoch [6/10], Batch [60/117], Total Loss: 4.4009, Triplet Loss: 0.1989, Adv Loss: 4.2020, Disc Loss: 0.0363\n",
      "Epoch [6/10], Batch [70/117], Total Loss: 4.5381, Triplet Loss: 0.1946, Adv Loss: 4.3436, Disc Loss: 0.0393\n",
      "Epoch [6/10], Batch [80/117], Total Loss: 4.2075, Triplet Loss: 0.1411, Adv Loss: 4.0664, Disc Loss: 0.0375\n",
      "Epoch [6/10], Batch [90/117], Total Loss: 4.2555, Triplet Loss: 0.2728, Adv Loss: 3.9828, Disc Loss: 0.0450\n",
      "Epoch [6/10], Batch [100/117], Total Loss: 4.1969, Triplet Loss: 0.2198, Adv Loss: 3.9770, Disc Loss: 0.0469\n",
      "Epoch [6/10], Batch [110/117], Total Loss: 4.2224, Triplet Loss: 0.1490, Adv Loss: 4.0735, Disc Loss: 0.0516\n",
      "Epoch [6/10] Completed. Avg Total Loss: 4.2872, Avg Triplet Loss: 0.1762, Avg Adv Loss: 4.1110, Avg Disc Loss: 0.0432\n",
      "Validation Loss: 4.0594, Triplet Loss: 0.1888, Adv Loss: 3.8705, Pos Sim: 1.0000, Neg Sim: 0.9112\n",
      "Validation Loss after Epoch 6: 4.0594\n",
      "Model checkpoint saved at ../../data/logs/mol2dreams/20241010_143012_mol2dreams/model_epoch_6.pt\n",
      "Epoch [7/10], Batch [0/117], Total Loss: 4.1952, Triplet Loss: 0.1856, Adv Loss: 4.0096, Disc Loss: 0.0403\n",
      "Epoch [7/10], Batch [10/117], Total Loss: 4.1895, Triplet Loss: 0.1810, Adv Loss: 4.0085, Disc Loss: 0.0357\n",
      "Epoch [7/10], Batch [20/117], Total Loss: 4.6145, Triplet Loss: 0.1951, Adv Loss: 4.4193, Disc Loss: 0.0277\n",
      "Epoch [7/10], Batch [30/117], Total Loss: 4.8715, Triplet Loss: 0.2141, Adv Loss: 4.6573, Disc Loss: 0.0228\n",
      "Epoch [7/10], Batch [40/117], Total Loss: 4.6815, Triplet Loss: 0.2475, Adv Loss: 4.4340, Disc Loss: 0.0233\n",
      "Epoch [7/10], Batch [50/117], Total Loss: 4.6319, Triplet Loss: 0.1084, Adv Loss: 4.5235, Disc Loss: 0.0273\n",
      "Epoch [7/10], Batch [60/117], Total Loss: 5.4474, Triplet Loss: 0.1069, Adv Loss: 5.3405, Disc Loss: 0.0172\n",
      "Epoch [7/10], Batch [70/117], Total Loss: 5.4288, Triplet Loss: 0.1183, Adv Loss: 5.3104, Disc Loss: 0.0185\n",
      "Epoch [7/10], Batch [80/117], Total Loss: 4.9392, Triplet Loss: 0.1258, Adv Loss: 4.8133, Disc Loss: 0.0224\n",
      "Epoch [7/10], Batch [90/117], Total Loss: 4.8354, Triplet Loss: 0.1185, Adv Loss: 4.7170, Disc Loss: 0.0295\n",
      "Epoch [7/10], Batch [100/117], Total Loss: 5.1192, Triplet Loss: 0.1251, Adv Loss: 4.9941, Disc Loss: 0.0255\n",
      "Epoch [7/10], Batch [110/117], Total Loss: 5.1503, Triplet Loss: 0.1332, Adv Loss: 5.0171, Disc Loss: 0.0321\n",
      "Epoch [7/10] Completed. Avg Total Loss: 4.8749, Avg Triplet Loss: 0.1497, Avg Adv Loss: 4.7252, Avg Disc Loss: 0.0261\n",
      "Epoch [8/10], Batch [0/117], Total Loss: 4.7503, Triplet Loss: 0.1329, Adv Loss: 4.6174, Disc Loss: 0.0293\n",
      "Epoch [8/10], Batch [10/117], Total Loss: 5.1279, Triplet Loss: 0.1380, Adv Loss: 4.9900, Disc Loss: 0.0317\n",
      "Epoch [8/10], Batch [20/117], Total Loss: 4.9436, Triplet Loss: 0.1516, Adv Loss: 4.7920, Disc Loss: 0.0262\n",
      "Epoch [8/10], Batch [30/117], Total Loss: 4.9955, Triplet Loss: 0.1114, Adv Loss: 4.8841, Disc Loss: 0.0282\n",
      "Epoch [8/10], Batch [40/117], Total Loss: 5.2723, Triplet Loss: 0.2194, Adv Loss: 5.0529, Disc Loss: 0.0393\n",
      "Epoch [8/10], Batch [50/117], Total Loss: 4.4081, Triplet Loss: 0.2101, Adv Loss: 4.1980, Disc Loss: 0.0409\n",
      "Epoch [8/10], Batch [60/117], Total Loss: 4.6905, Triplet Loss: 0.1705, Adv Loss: 4.5200, Disc Loss: 0.0423\n",
      "Epoch [8/10], Batch [70/117], Total Loss: 4.4901, Triplet Loss: 0.2039, Adv Loss: 4.2861, Disc Loss: 0.0266\n",
      "Epoch [8/10], Batch [80/117], Total Loss: 4.5742, Triplet Loss: 0.2129, Adv Loss: 4.3613, Disc Loss: 0.0401\n",
      "Epoch [8/10], Batch [90/117], Total Loss: 4.7792, Triplet Loss: 0.1830, Adv Loss: 4.5962, Disc Loss: 0.0347\n",
      "Epoch [8/10], Batch [100/117], Total Loss: 4.8670, Triplet Loss: 0.2064, Adv Loss: 4.6607, Disc Loss: 0.0533\n",
      "Epoch [8/10], Batch [110/117], Total Loss: 4.7252, Triplet Loss: 0.2195, Adv Loss: 4.5058, Disc Loss: 0.0285\n",
      "Epoch [8/10] Completed. Avg Total Loss: 4.7511, Avg Triplet Loss: 0.1819, Avg Adv Loss: 4.5692, Avg Disc Loss: 0.0340\n",
      "Validation Loss: 4.6790, Triplet Loss: 0.1275, Adv Loss: 4.5515, Pos Sim: 1.0000, Neg Sim: 0.9725\n",
      "Validation Loss after Epoch 8: 4.6790\n",
      "Model checkpoint saved at ../../data/logs/mol2dreams/20241010_143012_mol2dreams/model_epoch_8.pt\n",
      "Epoch [9/10], Batch [0/117], Total Loss: 4.9216, Triplet Loss: 0.1633, Adv Loss: 4.7582, Disc Loss: 0.0435\n",
      "Epoch [9/10], Batch [10/117], Total Loss: 5.0336, Triplet Loss: 0.1939, Adv Loss: 4.8396, Disc Loss: 0.0452\n",
      "Epoch [9/10], Batch [20/117], Total Loss: 5.0606, Triplet Loss: 0.1883, Adv Loss: 4.8723, Disc Loss: 0.0266\n",
      "Epoch [9/10], Batch [30/117], Total Loss: 5.0811, Triplet Loss: 0.1747, Adv Loss: 4.9064, Disc Loss: 0.0321\n",
      "Epoch [9/10], Batch [40/117], Total Loss: 5.2026, Triplet Loss: 0.1921, Adv Loss: 5.0106, Disc Loss: 0.0194\n",
      "Epoch [9/10], Batch [50/117], Total Loss: 5.5482, Triplet Loss: 0.1114, Adv Loss: 5.4368, Disc Loss: 0.0158\n",
      "Epoch [9/10], Batch [60/117], Total Loss: 5.3987, Triplet Loss: 0.1219, Adv Loss: 5.2768, Disc Loss: 0.0168\n",
      "Epoch [9/10], Batch [70/117], Total Loss: 5.2529, Triplet Loss: 0.1122, Adv Loss: 5.1407, Disc Loss: 0.0200\n",
      "Epoch [9/10], Batch [80/117], Total Loss: 5.1104, Triplet Loss: 0.1203, Adv Loss: 4.9901, Disc Loss: 0.0199\n",
      "Epoch [9/10], Batch [90/117], Total Loss: 5.2381, Triplet Loss: 0.1493, Adv Loss: 5.0888, Disc Loss: 0.0214\n",
      "Epoch [9/10], Batch [100/117], Total Loss: 5.0885, Triplet Loss: 0.1124, Adv Loss: 4.9761, Disc Loss: 0.0216\n",
      "Epoch [9/10], Batch [110/117], Total Loss: 5.8586, Triplet Loss: 0.1390, Adv Loss: 5.7196, Disc Loss: 0.0145\n",
      "Epoch [9/10] Completed. Avg Total Loss: 5.2517, Avg Triplet Loss: 0.1523, Avg Adv Loss: 5.0994, Avg Disc Loss: 0.0218\n",
      "Epoch [10/10], Batch [0/117], Total Loss: 5.3373, Triplet Loss: 0.1444, Adv Loss: 5.1929, Disc Loss: 0.0170\n",
      "Epoch [10/10], Batch [10/117], Total Loss: 5.7619, Triplet Loss: 0.1260, Adv Loss: 5.6359, Disc Loss: 0.0269\n",
      "Epoch [10/10], Batch [20/117], Total Loss: 5.7466, Triplet Loss: 0.1300, Adv Loss: 5.6166, Disc Loss: 0.0211\n",
      "Epoch [10/10], Batch [30/117], Total Loss: 5.2762, Triplet Loss: 0.1346, Adv Loss: 5.1417, Disc Loss: 0.0539\n",
      "Epoch [10/10], Batch [40/117], Total Loss: 5.0041, Triplet Loss: 0.2865, Adv Loss: 4.7176, Disc Loss: 0.0619\n",
      "Epoch [10/10], Batch [50/117], Total Loss: 4.0390, Triplet Loss: 0.1414, Adv Loss: 3.8976, Disc Loss: 0.0499\n",
      "Epoch [10/10], Batch [60/117], Total Loss: 4.3997, Triplet Loss: 0.1357, Adv Loss: 4.2640, Disc Loss: 0.0397\n",
      "Epoch [10/10], Batch [70/117], Total Loss: 5.5486, Triplet Loss: 0.1419, Adv Loss: 5.4067, Disc Loss: 0.0288\n",
      "Epoch [10/10], Batch [80/117], Total Loss: 5.0598, Triplet Loss: 0.1698, Adv Loss: 4.8900, Disc Loss: 0.0243\n",
      "Epoch [10/10], Batch [90/117], Total Loss: 4.7947, Triplet Loss: 0.2975, Adv Loss: 4.4972, Disc Loss: 0.0301\n",
      "Epoch [10/10], Batch [100/117], Total Loss: 4.6982, Triplet Loss: 0.1598, Adv Loss: 4.5384, Disc Loss: 0.0249\n",
      "Epoch [10/10], Batch [110/117], Total Loss: 4.9724, Triplet Loss: 0.2122, Adv Loss: 4.7602, Disc Loss: 0.0254\n",
      "Epoch [10/10] Completed. Avg Total Loss: 5.0635, Avg Triplet Loss: 0.1774, Avg Adv Loss: 4.8861, Avg Disc Loss: 0.0352\n",
      "Validation Loss: 4.9943, Triplet Loss: 0.1483, Adv Loss: 4.8460, Pos Sim: 1.0000, Neg Sim: 0.9517\n",
      "Validation Loss after Epoch 10: 4.9943\n",
      "Model checkpoint saved at ../../data/logs/mol2dreams/20241010_143012_mol2dreams/model_epoch_10.pt\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T12:31:30.499090Z",
     "start_time": "2024-10-10T12:31:27.964948Z"
    }
   },
   "cell_type": "code",
   "source": "trainer.test()",
   "id": "76464651fc473ef6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 4.9956, Triplet Loss: 0.1497, Adv Loss: 4.8460, Pos Sim: 1.0000, Neg Sim: 0.9503\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T13:43:59.175795Z",
     "start_time": "2024-10-10T13:43:59.168992Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "def generate_tree(root_dir, prefix=\"\"):\n",
    "    tree_str = \"\"\n",
    "    items = sorted(os.listdir(root_dir))\n",
    "    for index, item in enumerate(items):\n",
    "        path = os.path.join(root_dir, item)\n",
    "        connector = \"└── \" if index == len(items) - 1 else \"├── \"\n",
    "        tree_str += prefix + connector + item + \"\\n\"\n",
    "        if os.path.isdir(path):\n",
    "            extension = \"    \" if index == len(items) - 1 else \"│   \"\n",
    "            tree_str += generate_tree(path, prefix + extension)\n",
    "    return tree_str\n",
    "\n"
   ],
   "id": "1ed9bf55944f5e62",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T13:44:00.562169Z",
     "start_time": "2024-10-10T13:44:00.555287Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Replace 'Tharwa' with the path to your root directory\n",
    "root_directory = \"/Users/macbook/CODE/mol2DreaMS/mol2dreams\"\n",
    "print(root_directory)\n",
    "print(generate_tree(root_directory))"
   ],
   "id": "f6265fd78b294f17",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/macbook/CODE/mol2DreaMS/mol2dreams\n",
      "├── .DS_Store\n",
      "├── __init__.py\n",
      "├── __pycache__\n",
      "│   └── __init__.cpython-311.pyc\n",
      "├── configs\n",
      "│   ├── local_config_adversarial_fine_tune_triplet.yaml\n",
      "│   ├── local_config_fine_tune_triplet.yaml\n",
      "│   ├── local_config_load_trained_model_simple_dataset.yaml\n",
      "│   ├── local_config_simple_dataset.yaml\n",
      "│   ├── local_config_train_cosin_loss.yaml\n",
      "│   ├── local_config_triplet_cosine_fine_tune.yaml\n",
      "│   └── local_config_triplet_margin.yaml\n",
      "├── datasets\n",
      "│   ├── SimpleDataset.py\n",
      "│   ├── TripletDataset.py\n",
      "│   ├── __init__.py\n",
      "│   ├── __pycache__\n",
      "│   │   ├── SimpleDataset.cpython-311.pyc\n",
      "│   │   ├── TripletDataset.cpython-311.pyc\n",
      "│   │   ├── __init__.cpython-311.pyc\n",
      "│   │   └── mocule_spectrum_dataset.cpython-311.pyc\n",
      "│   └── mocule_spectrum_dataset.py\n",
      "├── featurizer\n",
      "│   ├── __init__.py\n",
      "│   ├── __pycache__\n",
      "│   │   ├── __init__.cpython-311.pyc\n",
      "│   │   ├── atom_features.cpython-311.pyc\n",
      "│   │   ├── bond_features.cpython-311.pyc\n",
      "│   │   └── featurize.cpython-311.pyc\n",
      "│   ├── atom_features.py\n",
      "│   ├── bond_features.py\n",
      "│   └── featurize.py\n",
      "├── model\n",
      "│   ├── BodyLayer.py\n",
      "│   ├── HeadLayer.py\n",
      "│   ├── InputLayer.py\n",
      "│   ├── __init__.py\n",
      "│   ├── __pycache__\n",
      "│   │   ├── BodyLayer.cpython-311.pyc\n",
      "│   │   ├── HeadLayer.cpython-311.pyc\n",
      "│   │   ├── InputLayer.cpython-311.pyc\n",
      "│   │   ├── __init__.cpython-311.pyc\n",
      "│   │   ├── discriminator.cpython-311.pyc\n",
      "│   │   └── mol2dreams.cpython-311.pyc\n",
      "│   ├── discriminator.py\n",
      "│   └── mol2dreams.py\n",
      "├── notebooks\n",
      "│   ├── InfoNCE_contrastive_dataset_construction.ipynb\n",
      "│   ├── TripletMagrinLoss_dataset_construction.ipynb\n",
      "│   ├── fine_tune.ipynb\n",
      "│   ├── fine_tune_adversarial.ipynb\n",
      "│   ├── massspecgym_dreams_embedding.ipynb\n",
      "│   ├── model_testing.ipynb\n",
      "│   ├── model_training.ipynb\n",
      "│   └── molecule_feauturizer.ipynb\n",
      "├── scripts\n",
      "│   └── train.py\n",
      "├── trainer\n",
      "│   ├── __init__.py\n",
      "│   ├── __pycache__\n",
      "│   │   ├── __init__.cpython-311.pyc\n",
      "│   │   ├── loss.cpython-311.pyc\n",
      "│   │   └── trainer.cpython-311.pyc\n",
      "│   ├── loss.py\n",
      "│   └── trainer.py\n",
      "└── utils\n",
      "    ├── __init__.py\n",
      "    ├── __pycache__\n",
      "    │   ├── __init__.cpython-311.pyc\n",
      "    │   ├── data.cpython-311.pyc\n",
      "    │   ├── gradient_penalty.cpython-311.pyc\n",
      "    │   ├── layers.cpython-311.pyc\n",
      "    │   ├── metrics.cpython-311.pyc\n",
      "    │   └── parser.cpython-311.pyc\n",
      "    ├── data.py\n",
      "    ├── gradient_penalty.py\n",
      "    ├── layers.py\n",
      "    ├── metrics.py\n",
      "    └── parser.py\n",
      "\n"
     ]
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
